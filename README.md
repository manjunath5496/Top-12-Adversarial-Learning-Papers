# Top 12 Adversarial Learning Papers

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(1).pdf" style="text-decoration:none;">DaST: Data-free Substitute Training for Adversarial Attacks</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(2).pdf" style="text-decoration:none;">The Secret Revealer: Generative Model-Inversion Attacks Against Deep Neural Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(3).pdf" style="text-decoration:none;">Robustness Guarantees for Deep Neural Networks on Videos</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(4).pdf" style="text-decoration:none;">A Self-supervised Approach for Adversarial Robustness</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(5).pdf" style="text-decoration:none;">Towards Verifying Robustness of Neural Networks Against A Family of Semantic Perturbations</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(6).pdf" style="text-decoration:none;">Unpaired Image Super-Resolution using Pseudo-Supervision</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(7).pdf" style="text-decoration:none;">How Does Noise Help Robustness? Explanation and Exploration under the Neural SDE Framework</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(8).pdf" style="text-decoration:none;"> Adversarial Vertex Mixup: Toward Better Adversarially Robust Generalization </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(9).pdf" style="text-decoration:none;">Universal Litmus Patterns: Revealing Backdoor Attacks in CNNs</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(10).pdf" style="text-decoration:none;">Benchmarking Adversarial Robustness on Image Classification </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(11).pdf" style="text-decoration:none;">What it Thinks is Important is Important: Robustness Transfers through Input Gradients</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Top-12-Adversarial-Learning-Papers/blob/master/a(12).pdf" style="text-decoration:none;">Transferable, Controllable, and Inconspicuous Adversarial Attacks on Person Re-identificationWith Deep Mis-Ranking</a></li>
</ul>
